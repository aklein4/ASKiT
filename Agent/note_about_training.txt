
searcher-top_1:
    - bs = 24, lr = 1e-6, AdamW
    - linear schedular: 50000 steps with 10000 warmup
    - frens = 1, top_k = 5, noise_decay=2
    - trained on TopKCrossEntropy

searcher-top_2:
    - resumed training of searcher-top_2
    - bs = 24, lr = 1e-6, AdamW
    - Half-Cosine schedular: 100000 steps with 10000 warmup
    - frens = 1, top_k = 5, noise_decay=2
    - trained on TopKCrossEntropy

searcher-p:
    - Trained on THE FIRST 20,000 ELEMENTS OF TRAINING DATA (validated on normal val set)
    - bs=24, lr = 1e-6, AdamW
    - Half-Cosine schedular: 50000 steps with 10000 warmup
    - frens = 1, noise_decay=2
    - Used search_head = identity
    - Uses MaxPLoss over all inputs (no top_k)
    - Scaling/adding bias to the final result does not help

chooser-cls:
    - Trained on THE FIRST 20,000 ELEMENTS OF TRAINING DATA (validated on normal val set)
    - bs=4, lr = 1e-6, AdamW
    - Half-Cosine schedular: 80000 steps with 15000 warmup, killed after 40,000 steps
    - frens = 1, noise_decay = 2, top_k = 10
    - Used cls token embedding, head = [256->64], [dropout: p=0.1], [64->1]

chooser-nat:
    - Trained on THE FIRST 20,000 ELEMENTS OF TRAINING DATA (validated on normal val set)
    - bs=4, lr = 1e-6, AdamW
    - Half-Cosine schedular: 80000 steps with 15000 warmup, killed after 20,000 steps
    - frens = 1, noise_decay = 2, top_k = 10
    - Used pooled output, with single linear layer into scalar

agent:
    - train_acc: 0.325, train_f1: 0.669 on first 20000/skip

* This is a good question from Hotpot to use as an example:
    - Which California university has more established relationships with Asian researchers, University of Southern California or Stanford University?